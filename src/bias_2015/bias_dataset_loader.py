"""
Load in the data files that will be used in the Bitscopic Interpreting ACMG Standards (BIAS) variant interpretation
process

The input files can be generated by running the preprocessing.py script in the root directory.
"""
import re
import sys


# PVS1 caveat
def calculate_3prime_region(chrom, strand, exon_starts, exon_ends, exon_frames):
    """
    Identify the final coding exon, then identify the last 50 bases. Return the
    region which spans these 50 bases as a tuple (chrom, start, stop).
    """
    # Only consider exons that are considered in-frame (exclude out of frame exons)
    coding_exon_starts = []
    coding_exon_ends = []
    exon_count = len(exon_starts)
    for x in range(0, exon_count):
        if exon_frames[x] == '-1':
            continue
        coding_exon_starts.append(exon_starts[x])
        coding_exon_ends.append(exon_ends[x])

    if not coding_exon_ends: return () 
    # For the positive strand, use the last exon
    if strand == "+":
        last_exon_end = coding_exon_ends[-1]
        start_3prime = last_exon_end - 50
        end_3prime = last_exon_end
    else: # For the negative strand, use the first exon
        first_exon_start = coding_exon_starts[0]
        end_3prime = first_exon_start + 50
        start_3prime = first_exon_start

    return chrom, start_3prime, end_3prime

# PVS1 Caveate 2
def get_gene_name_to_3prime_region(ncbi_ref_seq_hgmd_fp):
    """
    Load RefSeq hg19 data into a dictionary that maps gene name to the final 50 bases
    of coding region

    In general, nonsense-mediated decay NMD is not predicted to occur if the premature termination codon occurs in the 
    3′ most exon or within the 3′ most 50 nucleotides of the penultimate exon (Chang, Imam, & Wilkinson, 2007; Lewis,
    Green, & Brenner, 2003). When NMD is not predicted to occur, it is important to determine if the truncated or
    altered region is critical to protein function, often indicated by experimental or clinical evidence—such as
    pathogenic variants downstream of the new stop codon—supporting the biological relevance of the C-terminal region.

    Chang, Y. F., Imam, J. S., & Wilkinson, M. F. (2007). The nonsense-mediated decay RNA surveillance pathway. Annual 
        Review of Biochemistry, 76, 51–74. DOI: 10.1146/annurev.biochem.76.050106.093909
    
    Lewis, B. P., Green, R. E., & Brenner, S. E. (2003). Evidence for the widespread coupling of alternative splicing
        and nonsense-mediated mRNA decay in humans. Proceedings of the National Academy of Sciences, 100(1), 189-192.
        DOI: 10.1073/pnas.0136770100
    """
    gene_name_to_3prime_region = {}
    with open(ncbi_ref_seq_hgmd_fp, 'r') as in_file:
        for line in in_file:
            fields = line.strip().split("\t")
            chrom = fields[2]
            strand = fields[3]
            exon_starts = list(map(int, fields[9].strip()[:-1].split(",")))
            exon_ends = list(map(int, fields[10].strip()[:-1].split(",")))
            exon_frames = fields[-1].split(",")
            gene_name = fields[12]  # Extracting the gene name
            region = calculate_3prime_region(chrom, strand, exon_starts, exon_ends, exon_frames)
            if region:
                gene_name_to_3prime_region[gene_name] = region
    if not gene_name_to_3prime_region:
        print(f"File {ncbi_ref_seq_hgmd_fp} does not have any valid entries!")
        sys.exit(1)
    return gene_name_to_3prime_region


def get_aa_comparator(p_notation):
    """
    AA look like 'Y524S', 'E525K', 'V552fsS26*', we want to compare the first AA and position
    to the current variant
    """
    first_half = ""
    pos_read = True
    nums = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']
    for char in p_notation:
        if char in nums:
            pos_read = False
        if not pos_read and char not in nums:
            break
        first_half += char
    return first_half


# PS1
def get_gene_mut_to_data(clinvar_pathogenic_aa_fp):
    """
    Load in amino acid changes that are associated with known pathogenic and likely pathogenic variants.
    """
    gene_mut_to_data = {}
    gene_aa_to_var_data = {}
    with open(clinvar_pathogenic_aa_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) < 7:
                continue
            gene_name, p_notation, rs_id, criteria, signif, clinvar_id, consequence = split_line
            gene_mut = (gene_name, p_notation)
            if gene_mut in gene_mut_to_data:
                gene_mut_to_data[gene_mut].append((rs_id, criteria, signif, clinvar_id))
            else:
                gene_mut_to_data[gene_mut] = [(rs_id, criteria, signif, clinvar_id)]
            if consequence == 'missense_variant':
                aa_change = get_aa_comparator(p_notation)
                gene_aa = (gene_name, aa_change)
                if gene_aa in gene_aa_to_var_data:
                    gene_aa_to_var_data[gene_aa].append((p_notation, rs_id, criteria, signif, clinvar_id))
                else:
                    gene_aa_to_var_data[gene_aa] = [(p_notation, rs_id, criteria, signif, clinvar_id)]
    if not gene_mut_to_data:
        print(f"File {clinvar_pathogenic_aa_fp} does not have any valid entries!")
        sys.exit(1)
    return gene_mut_to_data, gene_aa_to_var_data


def extract_floats(input_string):
    """
    Extract two floats from a string containing a dash-separated interval (e.g. "[1.04-1.1]").
    Falls back to a simpler match if no dash-based interval is found.
    """
    # 1) Try to match a dash-separated interval like [1.04-1.1] or (1.04-1.1)
    #    This regex allows optional brackets/parentheses and optional spaces.
    interval_pattern = r'[\[\(\s]*(-?\d+(?:\.\d+)?)\s*-\s*(-?\d+(?:\.\d+)?)[\)\]\s]*'
    match = re.search(interval_pattern, input_string)
    if match:
        ci_lower = float(match.group(1))
        ci_upper = float(match.group(2))
        return ci_lower, ci_upper

    # 2) Fallback to your original approach: just find all floats (including negative)
    pattern = r'(-?\d+\.\d+)'
    matches = re.findall(pattern, input_string)
    
    first_float = last_float = 0.0
    if len(matches) >= 2:
        first_float = float(matches[0])
        last_float = float(matches[-1])

    return first_float, last_float

# PS4
def get_dbsnpids_to_or(gwas_dbsnp_fp):
    """
    The NHGRI-EBI GWAS Catalog is a curated collection of all published genome-wide association studies, produced by a 
    collaboration between EMBL-EBI and the National Human Genome Research Institute (NHGRI). It includes comprehensive 
    data on SNP-trait associations with genome-wide significance.

    Hindorff LA, Sethupathy P, Junkins HA, Ramos EM, Mehta JP, Collins FS, Manolio TA. Potential etiologic and
        functional implications of genome-wide association loci for human diseases and traits. Proc Natl Acad Sci U S A.
        2009 Jun 9;106(23):9362-7. PMID: 19474294; PMC: PMC2687147

    The NHGRI-EBI GWAS Catalog: a curated resource of SNP-trait associations. Buniello, A., MacArthur, J.A.L., 
        Cerezo, M., et al. Nucleic Acids Research, 2019, 47(D1): D1005-D1012. 
        https://academic.oup.com/nar/article/47/D1/D1005/5184712

    """
    # Map chrom to pos
    chrom_to_pos_to_gwas_data = {}
    with open(gwas_dbsnp_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) < 23: continue
            chrom, start, stop, rs_id, pubmed_id = split_line[1:6]
            trait = split_line[9]
            p_value = split_line[17]
            or_value = split_line[19]
            if not or_value: continue
            or_value = float(or_value)
            p_value = float(p_value)
            ci_text = split_line[20]
            ci_lower, ci_upper = extract_floats(ci_text.split(" ")[0])
            data = (or_value, float(ci_lower), float(ci_upper), pubmed_id, trait, p_value, rs_id)
            for pos in range(int(start), int(stop)):
                if chrom_to_pos_to_gwas_data.get(chrom):
                    chrom_to_pos_to_gwas_data[chrom][pos] = data
                else:
                    chrom_to_pos_to_gwas_data[chrom] = {pos: data}
    if not chrom_to_pos_to_gwas_data:
        print(f"File {gwas_dbsnp_fp} does not have any valid entries!")
        sys.exit(1)
    return chrom_to_pos_to_gwas_data

# PM1
def get_chrom_to_pathogenic_domain_list(pathogenic_domains_fp):
    """
    Load in the pathogenic domains that are identified using Clinvar (see variant documentation) and the
    UCSC Genome Browser hg19 UniProt track

    UniProt Consortium. Reorganizing the protein space at the Universal Protein Resource (UniProt).
        Nucleic Acids Res. 2012 Jan;40(Database issue):D71-5. PMID: 22102590; PMC: PMC3245120

    Yip YL, Scheib H, Diemand AV, Gattiker A, Famiglietti LM, Gasteiger E, Bairoch A. The Swiss-Prot variant page and
        the ModSNP database: a resource for sequence and structure information on human protein variants.
        Hum Mutat. 2004 May;23(5):464-70. PMID: 15108278
    """
    chrom_to_pathogenic_domains = {}
    with open(pathogenic_domains_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) < 11: continue
            chrom = split_line[0]
            start = int(split_line[1])
            stop = int(split_line[2])
            uniprot_acc = split_line[3]
            source = split_line[4]
            path_per = float(split_line[5])
            path_score = int(split_line[6])
            benign_per = float(split_line[7])
            benign_score = float(split_line[8])
            total_score = float(split_line[9])
            ben_path_ratio = float(split_line[10])
            if chrom_to_pathogenic_domains.get(chrom):
                chrom_to_pathogenic_domains[chrom].append((start, stop, uniprot_acc, path_per, path_score, benign_per, benign_score, total_score, source, ben_path_ratio))
            else:
                chrom_to_pathogenic_domains[chrom] = [(start, stop, uniprot_acc, path_per, path_score, benign_per, benign_score, total_score, source, ben_path_ratio)]
    if not chrom_to_pathogenic_domains:
        print(f"File {pathogenic_domains_fp} does not have any valid entries!")
        sys.exit(1)
    return chrom_to_pathogenic_domains


# PM4
def get_chrom_to_repeat_regions(coding_repeat_region_fp):
    """
    UCSC repeat masker regions intersected with coding regions returned as a
    dict mapping chrom as a string to a list of repeat regions
    

    Repeat Masker:
    Smit AFA, Hubley R, Green P. RepeatMasker Open-3.0. http://www.repeatmasker.org. 1996-2010.

    Repbase Update is described in:

    Jurka J. Repbase Update: a database and an electronic journal of repetitive elements. Trends Genet.
        2000 Sep;16(9):418-420. PMID: 10973072

    For a discussion of repeats in mammalian genomes, see:

    Smit AF. Interspersed repeats and other mementos of transposable elements in mammalian genomes. Curr Opin Genet
        Dev. 1999 Dec;9(6):657-63. PMID: 10607616

    Smit AF. The origin of interspersed repeats in the human genome. Curr Opin Genet Dev. 1996 Dec;6(6):743-8.
        PMID: 8994846

    Consensus Coding:
    Hubbard T, Barker D, Birney E, Cameron G, Chen Y, Clark L, Cox T, Cuff J, Curwen V, Down T et al. The Ensembl
        genome database project. Nucleic Acids Res. 2002 Jan 1;30(1):38-41. PMID: 11752248; PMC: PMC99161

    Pruitt KD, Harrow J, Harte RA, Wallin C, Diekhans M, Maglott DR, Searle S, Farrell CM, Loveland JE, Ruef BJ et al. 
        The consensus coding sequence (CCDS) project: Identifying a common protein-coding gene set for the human and
        mouse genomes. Genome Res. 2009 Jul;19(7):1316-23. PMID: 19498102; PMC: PMC2704439

    Pruitt KD, Tatusova T, Maglott DR. NCBI Reference Sequence (RefSeq): a curated non-redundant sequence database of
        genomes, transcripts and proteins. Nucleic Acids Res. 2005 Jan 1;33(Database issue):D501-4. PMID: 15608248;
        PMC: PMC539979

    """
    chrom_to_repeat_regions = {}
    with open(coding_repeat_region_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) < 4: continue
            chrom, start, stop, strand = split_line
            region = (int(start), int(stop), strand)
            chrom_to_repeat_regions.setdefault(chrom, []).append(region)
    if not chrom_to_repeat_regions:
        print(f"File {coding_repeat_region_fp} does not have any valid entries!")
        sys.exit(1)
    return chrom_to_repeat_regions

# PP2 
def get_missense_pathogenic_gene_to_region_list(missense_pathogenic_gene_to_region_list_fp):
    """
    Load in genes where missense is a common mechanism of pathogenicity
    """
    missense_pathogenic_gene_to_region_list = {}

    with open(missense_pathogenic_gene_to_region_list_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) < 6: continue
            gene, start, end, oe, path_per, ben_per = split_line
            if oe:
                oe = float(oe)
            if missense_pathogenic_gene_to_region_list.get(gene):
                missense_pathogenic_gene_to_region_list[gene].append((int(start), int(end), oe, float(path_per), float(ben_per)))
            else:
                missense_pathogenic_gene_to_region_list[gene] = [(int(start), int(end), oe, float(path_per), float(ben_per))]
    if not missense_pathogenic_gene_to_region_list:
        print(f"File {missense_pathogenic_gene_to_region_list_fp} does not have any valid entries!")
        sys.exit(1)
    return missense_pathogenic_gene_to_region_list

# BP1 
def get_truncating_gene_to_data(truncating_gene_to_data_fp):
    """
    Genes identified from ClinVar where over 80% of pathogenic variants are truncating
    variants and where less than 20% of benign variants are truncating.
    """
    truncating_gene_to_data = {}
    with open(truncating_gene_to_data_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) < 3: continue
            gene, pathogenic_per, benign_per = split_line
            truncating_gene_to_data[gene] = (pathogenic_per, benign_per)
    if not truncating_gene_to_data:
        print(f"File {truncating_gene_to_data_fp} does not have any valid entries!")
        sys.exit(1)
    return truncating_gene_to_data


def get_benign_domains(benign_domains_fp):
    """
    Load in the benign domains that are identified using Clinvar (see variant documentation)
    """
    benign_domains = []
    with open(benign_domains_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) < 4: continue
            chrom = split_line[0]
            start = split_line[1]
            stop = split_line[2]
            uniprot_acc = split_line[3]
            benign_domains.append((chrom, start, stop, uniprot_acc))
    if not benign_domains:
        print(f"File {benign_domains_fp} does not have any valid entries!")
        sys.exit(1)
    return benign_domains

#PS3
def get_lit_gene_mut_to_data(lit_gene_aa_fp):
    """
    AVADA uses AI to find pathogenic variants from publications and link them to genomic coordinates.
    
    Johannes Birgmeier, Cole A. Deisseroth, Laura E. Hayward, Luisa M. T. Galhardo, Andrew P. Tierno, Karthik A.
        Jagadeesh, Peter D. Stenson, David N. Cooper, Jonathan A. Bernstein, Maximilian Haeussler, and Gill Bejerano.
        AVADA: Towards Automated Pathogenic Variant Evidence Retrieval Directly from the Full Text Literature.
        Genetics in Medicine. 2019. PMID: 31467448
    
    AVADA variants (gene, protein change) defined by AA change per gene and mapped to PubMed ID
    """
    lit_gene_mut_to_data = {}
    failed = False
    with open(lit_gene_aa_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) > 3:
                failed = True
            gene, prot_change, pubmed_id = split_line
            gene_mut = (gene, prot_change)
            if gene_mut in lit_gene_mut_to_data:
                lit_gene_mut_to_data[gene_mut].add(pubmed_id)
            else:
                lit_gene_mut_to_data[gene_mut] = {pubmed_id}
    if not lit_gene_mut_to_data:
        print(f"File {lit_gene_aa_fp} does not have any valid entries.")
        sys.exit(1)
    if failed:
        print(f"File {lit_gene_aa_fp} has bad entries! Please evaluate the file and remove the offending entries.")
        sys.exit(1)
    return lit_gene_mut_to_data


# PS3
def get_lit_variant_to_data(lit_variant_fp):
    """
    AVADA uses AI to find pathogenic variants from publications and link them to genomic coordinates.
    
    Johannes Birgmeier, Cole A. Deisseroth, Laura E. Hayward, Luisa M. T. Galhardo, Andrew P. Tierno, Karthik A.
        Jagadeesh, Peter D. Stenson, David N. Cooper, Jonathan A. Bernstein, Maximilian Haeussler, and Gill Bejerano.
        AVADA: Towards Automated Pathogenic Variant Evidence Retrieval Directly from the Full Text Literature.
        Genetics in Medicine. 2019. PMID: 31467448
    
    AVADA variants (chrom pos ref alt) defined by nucleotide and mapped to PubMed ID
    """
    lit_variant_to_data = {}
    failed = False
    with open(lit_variant_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) > 5:
                failed = True
                continue
            chrom, pos, ref, alt, pubmed_id = split_line
            variant = (chrom, pos, ref, alt)
            if variant in lit_variant_to_data:
                lit_variant_to_data[variant].add(pubmed_id)
            else:
                lit_variant_to_data[variant] = {pubmed_id}
    if not lit_variant_to_data:
        print(f"File {lit_variant_fp} does not have any valid entries.")
        sys.exit(1)
    if failed:
        print(f"File {lit_variant_fp} has bad entries! Please evaluate the file and remove the offending entries.")
        sys.exit(1)
    return lit_variant_to_data


def get_chrom_to_pos_to_alt_to_splice_score(ab_splice_fp):
    """
    AbSplice is a computational tool that predicts the likelihood of aberrant splicing caused by genetic variants across
    49 human tissues using tissue-specific splicing annotations derived from RNA-seq data. It assigns probabilistic 
    scores, with higher values indicating greater disruption potential, making it particularly useful for identifying
    tissue-relevant splicing defects. In the ACMG framework, AbSplice scores support criteria like PVS1 (null variants
    at splice sites), PS3/BS3 (functional evidence), and PP3/BP4 (in silico predictions), enabling precise classification
    of splice-related variants.

    Wagner N, Çelik MH, Hölzlwimmer FR, Mertes C, Prokisch H, Yépez VA, Gagneur J. Aberrant splicing prediction across 
        human tissues. Nat Genet. 2023 May;55(5):861-870. PMID: 37142848
    """
    chrom_to_pos_to_alt_to_splice_score = {}
    with open(ab_splice_fp, 'r') as in_file:
        for line in in_file:
            split_line = line.strip().split("\t")
            if len(split_line) > 4:
                continue
            chrom, pos, mut, score = split_line
            score = float(score)
            if len(mut) > 3: continue
            alt = mut[2]
            if chrom_to_pos_to_alt_to_splice_score.get(chrom):
                if chrom_to_pos_to_alt_to_splice_score[chrom].get(pos):
                    chrom_to_pos_to_alt_to_splice_score[chrom][pos][alt] = score
                else:
                    chrom_to_pos_to_alt_to_splice_score[chrom][pos] = {alt: score}
            else:
                chrom_to_pos_to_alt_to_splice_score[chrom] = {pos: {alt: score}}
    if not chrom_to_pos_to_alt_to_splice_score:
        print(f"File {ab_splice_fp} does not have any valid entries!")
        sys.exit(1)
    return chrom_to_pos_to_alt_to_splice_score

def get_name_to_dataset(file_paths):
    """
    Gather the datasets and format them for easy python consumption
    """
    name_to_dataset = {}
    name_to_dataset['PVS1_gene_name_to_3prime_region'] = get_gene_name_to_3prime_region(file_paths['PVS1_ncbi_ref_seq_hgmd_fp']) # PVS1 caveat
    name_to_dataset['PVS1_PP3_BP4_BP7_splice_dict'] = get_chrom_to_pos_to_alt_to_splice_score(file_paths['PVS1_PP3_BP4_BP7_splice_fp']) # PVS1/PP3/BP4/BP7 
    name_to_dataset['PS1_gene_mut_to_data'], name_to_dataset['PM5_gene_aa_to_var_data'] = get_gene_mut_to_data(file_paths['PS1_PM5_clinvar_pathogenic_aa_fp']) # PS1/PM5
    name_to_dataset['PS3_lit_gene_mut_to_data']  = get_lit_gene_mut_to_data(file_paths['PS3_literature_gene_aa_fp']) # PS3
    name_to_dataset['PS3_lit_variant_to_data'] = get_lit_variant_to_data(file_paths['PS3_literature_variant_fp']) # PS3
    name_to_dataset['PS4_chrom_to_pos_to_gwas_data'] = get_dbsnpids_to_or(file_paths['PS4_gwas_dbsnp_fp']) # PS4
    name_to_dataset['PM1_chrom_to_pathogenic_domain_list'] = get_chrom_to_pathogenic_domain_list(file_paths['PM1_chrom_to_pathogenic_domain_list_fp']) # PM1
    name_to_dataset['PM4_BP3_chrom_to_repeat_regions'] = get_chrom_to_repeat_regions(file_paths['PM4_BP3_coding_repeat_region_fp']) # PM4 & BP1
    name_to_dataset['PP2_missense_pathogenic_gene_to_region_list'] = get_missense_pathogenic_gene_to_region_list(file_paths['PP2_missense_pathogenic_gene_to_region_list_fp']) # PP2
    name_to_dataset['BP1_truncating_gene_to_data'] = get_truncating_gene_to_data(file_paths['BP1_truncating_gene_to_data_fp']) # BP1
    return name_to_dataset
